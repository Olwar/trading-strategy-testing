{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-11-30 22:00:00+00:00</th>\n",
       "      <td>1295.510254</td>\n",
       "      <td>1295.809082</td>\n",
       "      <td>1295.049683</td>\n",
       "      <td>1295.049683</td>\n",
       "      <td>1295.049683</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-30 22:05:00+00:00</th>\n",
       "      <td>1295.099365</td>\n",
       "      <td>1295.763306</td>\n",
       "      <td>1295.093018</td>\n",
       "      <td>1295.763306</td>\n",
       "      <td>1295.763306</td>\n",
       "      <td>12383232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-30 22:10:00+00:00</th>\n",
       "      <td>1295.908325</td>\n",
       "      <td>1295.908325</td>\n",
       "      <td>1295.148560</td>\n",
       "      <td>1295.148560</td>\n",
       "      <td>1295.148560</td>\n",
       "      <td>3593216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-30 22:15:00+00:00</th>\n",
       "      <td>1295.027100</td>\n",
       "      <td>1295.027100</td>\n",
       "      <td>1294.249390</td>\n",
       "      <td>1294.249390</td>\n",
       "      <td>1294.249390</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-30 22:20:00+00:00</th>\n",
       "      <td>1294.177490</td>\n",
       "      <td>1294.395996</td>\n",
       "      <td>1294.007812</td>\n",
       "      <td>1294.395996</td>\n",
       "      <td>1294.395996</td>\n",
       "      <td>11730944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Open         High          Low        Close  \\\n",
       "Datetime                                                                        \n",
       "2022-11-30 22:00:00+00:00  1295.510254  1295.809082  1295.049683  1295.049683   \n",
       "2022-11-30 22:05:00+00:00  1295.099365  1295.763306  1295.093018  1295.763306   \n",
       "2022-11-30 22:10:00+00:00  1295.908325  1295.908325  1295.148560  1295.148560   \n",
       "2022-11-30 22:15:00+00:00  1295.027100  1295.027100  1294.249390  1294.249390   \n",
       "2022-11-30 22:20:00+00:00  1294.177490  1294.395996  1294.007812  1294.395996   \n",
       "\n",
       "                             Adj Close    Volume  \n",
       "Datetime                                          \n",
       "2022-11-30 22:00:00+00:00  1295.049683         0  \n",
       "2022-11-30 22:05:00+00:00  1295.763306  12383232  \n",
       "2022-11-30 22:10:00+00:00  1295.148560   3593216  \n",
       "2022-11-30 22:15:00+00:00  1294.249390         0  \n",
       "2022-11-30 22:20:00+00:00  1294.395996  11730944  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# download ethereum data from yfinance\n",
    "eth = yf.download('ETH-USD', start='2022-12-01', end='2023-12-31', interval='5m')\n",
    "\n",
    "# convert to pandas dataframe\n",
    "eth = pd.DataFrame(eth)\n",
    "\n",
    "eth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-11-30 22:00:00+00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1295.049683</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-30 22:05:00+00:00</th>\n",
       "      <td>-0.000317</td>\n",
       "      <td>-0.000035</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000551</td>\n",
       "      <td>1295.763306</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-30 22:10:00+00:00</th>\n",
       "      <td>0.000625</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>-0.000474</td>\n",
       "      <td>1295.148560</td>\n",
       "      <td>-0.709832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-30 22:15:00+00:00</th>\n",
       "      <td>-0.000680</td>\n",
       "      <td>-0.000680</td>\n",
       "      <td>-0.000694</td>\n",
       "      <td>-0.000694</td>\n",
       "      <td>1294.249390</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-30 22:20:00+00:00</th>\n",
       "      <td>-0.000656</td>\n",
       "      <td>-0.000487</td>\n",
       "      <td>-0.000187</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>1294.395996</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Open      High       Low     Close  \\\n",
       "Datetime                                                            \n",
       "2022-11-30 22:00:00+00:00       NaN       NaN       NaN       NaN   \n",
       "2022-11-30 22:05:00+00:00 -0.000317 -0.000035  0.000033  0.000551   \n",
       "2022-11-30 22:10:00+00:00  0.000625  0.000112  0.000043 -0.000474   \n",
       "2022-11-30 22:15:00+00:00 -0.000680 -0.000680 -0.000694 -0.000694   \n",
       "2022-11-30 22:20:00+00:00 -0.000656 -0.000487 -0.000187  0.000113   \n",
       "\n",
       "                             Adj Close    Volume  \n",
       "Datetime                                          \n",
       "2022-11-30 22:00:00+00:00  1295.049683       NaN  \n",
       "2022-11-30 22:05:00+00:00  1295.763306       inf  \n",
       "2022-11-30 22:10:00+00:00  1295.148560 -0.709832  \n",
       "2022-11-30 22:15:00+00:00  1294.249390 -1.000000  \n",
       "2022-11-30 22:20:00+00:00  1294.395996       inf  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change all the values to percentage change\n",
    "eth['Open'] = eth['Open'].pct_change()\n",
    "eth['High'] = eth['High'].pct_change()\n",
    "eth['Low'] = eth['Low'].pct_change()\n",
    "eth['Close'] = eth['Close'].pct_change()\n",
    "eth['Volume'] = eth['Volume'].pct_change()\n",
    "\n",
    "eth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate how many datapoints in 1 day\n",
    "num_of_datapoints = int(24 * 60 / 5)\n",
    "\n",
    "eth['Close'] = eth['Close'].shift(-num_of_datapoints)\n",
    "\n",
    "# drop adj close column\n",
    "eth = eth.drop(['Adj Close'], axis=1)\n",
    "\n",
    "# drop nan values\n",
    "eth = eth.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Open         0\n",
       "High         0\n",
       "Low          0\n",
       "Close        0\n",
       "Volume    2383\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the number on infs\n",
    "eth.isin([np.inf, -np.inf]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change all the infs to 0\n",
    "eth = eth.replace([np.inf, -np.inf], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into x and y train and test using built-in function\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = eth.drop(['Close'], axis=1)\n",
    "y = eth['Close']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42, shuffle=False)\n",
    "\n",
    "# scale the data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-21 16:06:37.636495: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-01-21 16:06:37.636554: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8034, 288, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16242/546366864.py:20: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasRegressor(build_fn=create_model, verbose=0)\n",
      "2023-01-21 16:06:44.610546: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-01-21 16:06:44.611376: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-01-21 16:06:44.611479: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-01-21 16:06:44.611499: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-01-21 16:06:44.620682: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-01-21 16:06:44.620714: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-01-21 16:06:44.620732: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-01-21 16:06:44.620752: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-01-21 16:06:44.626644: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-01-21 16:06:44.626680: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-01-21 16:06:44.636086: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-01-21 16:06:44.636118: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-01-21 16:06:44.648766: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-01-21 16:06:44.648863: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-01-21 16:06:44.672387: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-01-21 16:06:44.672506: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-01-21 16:06:54.019275: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-01-21 16:06:54.019275: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-01-21 16:06:54.019431: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-01-21 16:06:54.020581: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-01-21 16:06:54.058123: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-01-21 16:06:54.058134: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-01-21 16:06:54.058167: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-01-21 16:06:54.058316: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (olli-UX430UNR): /proc/driver/nvidia/version does not exist\n",
      "2023-01-21 16:06:54.058316: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (olli-UX430UNR): /proc/driver/nvidia/version does not exist\n",
      "2023-01-21 16:06:54.058324: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (olli-UX430UNR): /proc/driver/nvidia/version does not exist\n",
      "2023-01-21 16:06:54.058933: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-01-21 16:06:54.059076: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (olli-UX430UNR): /proc/driver/nvidia/version does not exist\n",
      "2023-01-21 16:06:54.123376: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-01-21 16:06:54.123446: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-01-21 16:06:54.123519: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (olli-UX430UNR): /proc/driver/nvidia/version does not exist\n",
      "2023-01-21 16:06:54.137257: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-21 16:06:54.137303: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-21 16:06:54.137300: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-21 16:06:54.137293: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-21 16:06:54.137665: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-21 16:06:54.146182: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-01-21 16:06:54.146274: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-01-21 16:06:54.146348: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (olli-UX430UNR): /proc/driver/nvidia/version does not exist\n",
      "2023-01-21 16:06:54.147219: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-21 16:06:54.161813: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-01-21 16:06:54.161862: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-01-21 16:06:54.161899: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (olli-UX430UNR): /proc/driver/nvidia/version does not exist\n",
      "2023-01-21 16:06:54.162327: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-21 16:06:54.188479: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-01-21 16:06:54.188511: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-01-21 16:06:54.188536: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (olli-UX430UNR): /proc/driver/nvidia/version does not exist\n",
      "2023-01-21 16:06:54.188829: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/olli/Desktop/Koodauskr채채s채채/trading-strategy-testing/lstm_intraday_gridsearch.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 64>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/olli/Desktop/Koodauskr%C3%A4%C3%A4s%C3%A4%C3%A4/trading-strategy-testing/lstm_intraday_gridsearch.ipynb#X11sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m \u001b[39m# Perform the grid search\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/olli/Desktop/Koodauskr%C3%A4%C3%A4s%C3%A4%C3%A4/trading-strategy-testing/lstm_intraday_gridsearch.ipynb#X11sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m grid \u001b[39m=\u001b[39m GridSearchCV(estimator\u001b[39m=\u001b[39mmodel, param_grid\u001b[39m=\u001b[39mparam_grid, n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/olli/Desktop/Koodauskr%C3%A4%C3%A4s%C3%A4%C3%A4/trading-strategy-testing/lstm_intraday_gridsearch.ipynb#X11sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m grid_result \u001b[39m=\u001b[39m grid\u001b[39m.\u001b[39;49mfit(x_train_seq, y_train_seq, validation_data\u001b[39m=\u001b[39;49m(x_test_seq, y_test_seq))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/olli/Desktop/Koodauskr%C3%A4%C3%A4s%C3%A4%C3%A4/trading-strategy-testing/lstm_intraday_gridsearch.ipynb#X11sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m \u001b[39m# Print the best parameters and the corresponding score\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/olli/Desktop/Koodauskr%C3%A4%C3%A4s%C3%A4%C3%A4/trading-strategy-testing/lstm_intraday_gridsearch.ipynb#X11sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mBest: \u001b[39m\u001b[39m%f\u001b[39;00m\u001b[39m using \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (grid_result\u001b[39m.\u001b[39mbest_score_, grid_result\u001b[39m.\u001b[39mbest_params_))\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    869\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[1;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    871\u001b[0m     )\n\u001b[1;32m    873\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m--> 875\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[1;32m    877\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    879\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:1375\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1374\u001b[0m     \u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1375\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:822\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    815\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    817\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    818\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[1;32m    819\u001b[0m         )\n\u001b[1;32m    820\u001b[0m     )\n\u001b[0;32m--> 822\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    823\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    824\u001b[0m         clone(base_estimator),\n\u001b[1;32m    825\u001b[0m         X,\n\u001b[1;32m    826\u001b[0m         y,\n\u001b[1;32m    827\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[1;32m    828\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[1;32m    829\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[1;32m    830\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[1;32m    831\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[1;32m    832\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[1;32m    833\u001b[0m     )\n\u001b[1;32m    834\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[1;32m    835\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[1;32m    836\u001b[0m     )\n\u001b[1;32m    837\u001b[0m )\n\u001b[1;32m    839\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    840\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    844\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py:1056\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1053\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1055\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1056\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[1;32m   1057\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1058\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py:935\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    933\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    934\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m--> 935\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[1;32m    936\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    937\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py:542\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    540\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 542\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m    543\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    544\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.8/concurrent/futures/_base.py:439\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m    437\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[0;32m--> 439\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_condition\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    441\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    442\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m/usr/lib/python3.8/threading.py:302\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    301\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 302\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    303\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    304\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# LSTM model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "def create_model(optimizer='adam', dropout_rate=0.2, num_neurons=50):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(num_neurons, return_sequences=True))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(LSTM(num_neurons, return_sequences=False))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(25))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Create the model\n",
    "model = KerasRegressor(build_fn=create_model, verbose=0)\n",
    "\n",
    "# Define the grid search parameters\n",
    "optimizer = ['Adam', 'RMSprop']\n",
    "dropout_rate = [0.1, 0.2, 0.3]\n",
    "num_neurons = [50, 100, 150]\n",
    "batch_size = [1, 10, 20]\n",
    "epochs = [10, 20, 30]\n",
    "param_grid = dict(optimizer=optimizer, dropout_rate=dropout_rate, num_neurons=num_neurons, batch_size=batch_size, epochs=epochs)\n",
    "\n",
    "# Create an empty list to store the input and output sequences\n",
    "x_train_seq = []\n",
    "y_train_seq = []\n",
    "x_test_seq = []\n",
    "y_test_seq = []\n",
    "\n",
    "# Loop through the entire training dataset\n",
    "for i in range(num_of_datapoints, len(x_train)):\n",
    "    # Get one day's worth of data points from the training dataset\n",
    "    x_train_seq.append(x_train[i-num_of_datapoints:i, 0])\n",
    "    # Get the corresponding output (i.e. the next day's data points)\n",
    "    y_train_seq.append(y_train.iloc[i])\n",
    "\n",
    "# Loop through the entire testdataset\n",
    "for i in range(num_of_datapoints, len(x_test)):\n",
    "    # Get one day's worth of data points from the test dataset\n",
    "    x_test_seq.append(x_test[i-num_of_datapoints:i, 0])\n",
    "    # Get the corresponding output (i.e. the next day's data points)\n",
    "    y_test_seq.append(y_test.iloc[i])\n",
    "\n",
    "# Convert the input and output sequences to numpy arrays\n",
    "x_train_seq = np.array(x_train_seq)\n",
    "y_train_seq = np.array(y_train_seq)\n",
    "x_test_seq = np.array(x_test_seq)\n",
    "y_test_seq = np.array(y_test_seq)\n",
    "\n",
    "# Reshape the input data to match the LSTM's input shape\n",
    "x_train_seq = np.reshape(x_train_seq, (x_train_seq.shape[0], x_train_seq.shape[1], 1))\n",
    "x_test_seq = np.reshape(x_test_seq, (x_test_seq.shape[0], x_test_seq.shape[1], 1))\n",
    "\n",
    "print(x_train_seq.shape)\n",
    "\n",
    "# Perform the grid search\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1)\n",
    "grid_result = grid.fit(x_train_seq, y_train_seq, validation_data=(x_test_seq, y_test_seq))\n",
    "\n",
    "# Print the best parameters and the corresponding score\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "# plot the train and test loss\n",
    "plt.plot(model.history.history['loss'], label='train')\n",
    "plt.plot(model.history.history['val_loss'], label='test')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions on the test set\n",
    "y_pred = model.predict(x_test_seq)\n",
    "\n",
    "# calculate the MAE\n",
    "mae = mean_absolute_error(y_test_seq, y_pred)\n",
    "print(\"MAE:\", mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the prediction and the test set\n",
    "plt.plot(y_test_seq, label='test')\n",
    "plt.plot(y_pred, label='prediction')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, Nov 14 2022, 12:59:47) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
