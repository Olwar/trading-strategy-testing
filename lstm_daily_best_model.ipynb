{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-11-09</th>\n",
       "      <td>308.644989</td>\n",
       "      <td>329.451996</td>\n",
       "      <td>307.056000</td>\n",
       "      <td>320.884003</td>\n",
       "      <td>320.884003</td>\n",
       "      <td>893249984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-10</th>\n",
       "      <td>320.670990</td>\n",
       "      <td>324.717987</td>\n",
       "      <td>294.541992</td>\n",
       "      <td>299.252991</td>\n",
       "      <td>299.252991</td>\n",
       "      <td>885985984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-11</th>\n",
       "      <td>298.585999</td>\n",
       "      <td>319.453003</td>\n",
       "      <td>298.191986</td>\n",
       "      <td>314.681000</td>\n",
       "      <td>314.681000</td>\n",
       "      <td>842300992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-12</th>\n",
       "      <td>314.690002</td>\n",
       "      <td>319.153015</td>\n",
       "      <td>298.513000</td>\n",
       "      <td>307.907990</td>\n",
       "      <td>307.907990</td>\n",
       "      <td>1613479936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-13</th>\n",
       "      <td>307.024994</td>\n",
       "      <td>328.415009</td>\n",
       "      <td>307.024994</td>\n",
       "      <td>316.716003</td>\n",
       "      <td>316.716003</td>\n",
       "      <td>1041889984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close   Adj Close  \\\n",
       "Date                                                                     \n",
       "2017-11-09  308.644989  329.451996  307.056000  320.884003  320.884003   \n",
       "2017-11-10  320.670990  324.717987  294.541992  299.252991  299.252991   \n",
       "2017-11-11  298.585999  319.453003  298.191986  314.681000  314.681000   \n",
       "2017-11-12  314.690002  319.153015  298.513000  307.907990  307.907990   \n",
       "2017-11-13  307.024994  328.415009  307.024994  316.716003  316.716003   \n",
       "\n",
       "                Volume  \n",
       "Date                    \n",
       "2017-11-09   893249984  \n",
       "2017-11-10   885985984  \n",
       "2017-11-11   842300992  \n",
       "2017-11-12  1613479936  \n",
       "2017-11-13  1041889984  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# download ethereum data from yfinance\n",
    "eth = yf.download('ETH-USD', period='max', interval='1d')\n",
    "\n",
    "# convert to pandas dataframe\n",
    "eth = pd.DataFrame(eth)\n",
    "\n",
    "eth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>day_of_week</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-11-09</th>\n",
       "      <td>308.644989</td>\n",
       "      <td>329.451996</td>\n",
       "      <td>307.056000</td>\n",
       "      <td>320.884003</td>\n",
       "      <td>320.884003</td>\n",
       "      <td>893249984</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-10</th>\n",
       "      <td>320.670990</td>\n",
       "      <td>324.717987</td>\n",
       "      <td>294.541992</td>\n",
       "      <td>299.252991</td>\n",
       "      <td>299.252991</td>\n",
       "      <td>885985984</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-11</th>\n",
       "      <td>298.585999</td>\n",
       "      <td>319.453003</td>\n",
       "      <td>298.191986</td>\n",
       "      <td>314.681000</td>\n",
       "      <td>314.681000</td>\n",
       "      <td>842300992</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-12</th>\n",
       "      <td>314.690002</td>\n",
       "      <td>319.153015</td>\n",
       "      <td>298.513000</td>\n",
       "      <td>307.907990</td>\n",
       "      <td>307.907990</td>\n",
       "      <td>1613479936</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-13</th>\n",
       "      <td>307.024994</td>\n",
       "      <td>328.415009</td>\n",
       "      <td>307.024994</td>\n",
       "      <td>316.716003</td>\n",
       "      <td>316.716003</td>\n",
       "      <td>1041889984</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-18</th>\n",
       "      <td>1567.698975</td>\n",
       "      <td>1602.106689</td>\n",
       "      <td>1509.422852</td>\n",
       "      <td>1515.506958</td>\n",
       "      <td>1515.506958</td>\n",
       "      <td>10354880595</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-19</th>\n",
       "      <td>1515.249634</td>\n",
       "      <td>1557.970337</td>\n",
       "      <td>1514.380005</td>\n",
       "      <td>1552.556519</td>\n",
       "      <td>1552.556519</td>\n",
       "      <td>6432638856</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-20</th>\n",
       "      <td>1552.373657</td>\n",
       "      <td>1659.885742</td>\n",
       "      <td>1544.917847</td>\n",
       "      <td>1659.754150</td>\n",
       "      <td>1659.754150</td>\n",
       "      <td>8528894754</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-21</th>\n",
       "      <td>1659.706055</td>\n",
       "      <td>1674.179321</td>\n",
       "      <td>1626.812988</td>\n",
       "      <td>1627.118164</td>\n",
       "      <td>1627.118164</td>\n",
       "      <td>8859250310</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-22</th>\n",
       "      <td>1626.634399</td>\n",
       "      <td>1634.360718</td>\n",
       "      <td>1615.798096</td>\n",
       "      <td>1625.248535</td>\n",
       "      <td>1625.248535</td>\n",
       "      <td>8599992320</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1901 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Open         High          Low        Close    Adj Close  \\\n",
       "Date                                                                          \n",
       "2017-11-09   308.644989   329.451996   307.056000   320.884003   320.884003   \n",
       "2017-11-10   320.670990   324.717987   294.541992   299.252991   299.252991   \n",
       "2017-11-11   298.585999   319.453003   298.191986   314.681000   314.681000   \n",
       "2017-11-12   314.690002   319.153015   298.513000   307.907990   307.907990   \n",
       "2017-11-13   307.024994   328.415009   307.024994   316.716003   316.716003   \n",
       "...                 ...          ...          ...          ...          ...   \n",
       "2023-01-18  1567.698975  1602.106689  1509.422852  1515.506958  1515.506958   \n",
       "2023-01-19  1515.249634  1557.970337  1514.380005  1552.556519  1552.556519   \n",
       "2023-01-20  1552.373657  1659.885742  1544.917847  1659.754150  1659.754150   \n",
       "2023-01-21  1659.706055  1674.179321  1626.812988  1627.118164  1627.118164   \n",
       "2023-01-22  1626.634399  1634.360718  1615.798096  1625.248535  1625.248535   \n",
       "\n",
       "                 Volume  day_of_week  \n",
       "Date                                  \n",
       "2017-11-09    893249984            3  \n",
       "2017-11-10    885985984            4  \n",
       "2017-11-11    842300992            5  \n",
       "2017-11-12   1613479936            6  \n",
       "2017-11-13   1041889984            0  \n",
       "...                 ...          ...  \n",
       "2023-01-18  10354880595            2  \n",
       "2023-01-19   6432638856            3  \n",
       "2023-01-20   8528894754            4  \n",
       "2023-01-21   8859250310            5  \n",
       "2023-01-22   8599992320            6  \n",
       "\n",
       "[1901 rows x 7 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add a column for day of the week\n",
    "eth['day_of_week'] = eth.index.dayofweek\n",
    "\n",
    "eth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>day_of_week</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-11-09</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-10</th>\n",
       "      <td>0.038964</td>\n",
       "      <td>-0.014369</td>\n",
       "      <td>-0.040755</td>\n",
       "      <td>-0.067411</td>\n",
       "      <td>-0.067411</td>\n",
       "      <td>-0.008132</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-11</th>\n",
       "      <td>-0.068871</td>\n",
       "      <td>-0.016214</td>\n",
       "      <td>0.012392</td>\n",
       "      <td>0.051555</td>\n",
       "      <td>0.051555</td>\n",
       "      <td>-0.049307</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-12</th>\n",
       "      <td>0.053934</td>\n",
       "      <td>-0.000939</td>\n",
       "      <td>0.001077</td>\n",
       "      <td>-0.021523</td>\n",
       "      <td>-0.021523</td>\n",
       "      <td>0.915562</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-13</th>\n",
       "      <td>-0.024357</td>\n",
       "      <td>0.029021</td>\n",
       "      <td>0.028515</td>\n",
       "      <td>0.028606</td>\n",
       "      <td>0.028606</td>\n",
       "      <td>-0.354259</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Open      High       Low     Close  Adj Close    Volume  \\\n",
       "Date                                                                      \n",
       "2017-11-09       NaN       NaN       NaN       NaN        NaN       NaN   \n",
       "2017-11-10  0.038964 -0.014369 -0.040755 -0.067411  -0.067411 -0.008132   \n",
       "2017-11-11 -0.068871 -0.016214  0.012392  0.051555   0.051555 -0.049307   \n",
       "2017-11-12  0.053934 -0.000939  0.001077 -0.021523  -0.021523  0.915562   \n",
       "2017-11-13 -0.024357  0.029021  0.028515  0.028606   0.028606 -0.354259   \n",
       "\n",
       "            day_of_week  \n",
       "Date                     \n",
       "2017-11-09            3  \n",
       "2017-11-10            4  \n",
       "2017-11-11            5  \n",
       "2017-11-12            6  \n",
       "2017-11-13            0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change all the values to percentage change\n",
    "eth['Open'] = eth['Open'].pct_change()\n",
    "eth['High'] = eth['High'].pct_change()\n",
    "eth['Low'] = eth['Low'].pct_change()\n",
    "eth['Close'] = eth['Close'].pct_change()\n",
    "eth['Volume'] = eth['Volume'].pct_change()\n",
    "eth['Adj Close'] = eth['Adj Close'].pct_change()\n",
    "\n",
    "eth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>day_of_week</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-11-09</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-10</th>\n",
       "      <td>0.038964</td>\n",
       "      <td>-0.014369</td>\n",
       "      <td>-0.040755</td>\n",
       "      <td>-0.067411</td>\n",
       "      <td>320.884003</td>\n",
       "      <td>-0.008132</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-11</th>\n",
       "      <td>-0.068871</td>\n",
       "      <td>-0.016214</td>\n",
       "      <td>0.012392</td>\n",
       "      <td>0.051555</td>\n",
       "      <td>299.252991</td>\n",
       "      <td>-0.049307</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-12</th>\n",
       "      <td>0.053934</td>\n",
       "      <td>-0.000939</td>\n",
       "      <td>0.001077</td>\n",
       "      <td>-0.021523</td>\n",
       "      <td>314.681000</td>\n",
       "      <td>0.915562</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-13</th>\n",
       "      <td>-0.024357</td>\n",
       "      <td>0.029021</td>\n",
       "      <td>0.028515</td>\n",
       "      <td>0.028606</td>\n",
       "      <td>307.907990</td>\n",
       "      <td>-0.354259</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-18</th>\n",
       "      <td>-0.005966</td>\n",
       "      <td>0.005085</td>\n",
       "      <td>-0.028270</td>\n",
       "      <td>-0.033383</td>\n",
       "      <td>1567.846069</td>\n",
       "      <td>0.362581</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-19</th>\n",
       "      <td>-0.033456</td>\n",
       "      <td>-0.027549</td>\n",
       "      <td>0.003284</td>\n",
       "      <td>0.024447</td>\n",
       "      <td>1515.506958</td>\n",
       "      <td>-0.378782</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-20</th>\n",
       "      <td>0.024500</td>\n",
       "      <td>0.065415</td>\n",
       "      <td>0.020165</td>\n",
       "      <td>0.069046</td>\n",
       "      <td>1552.556519</td>\n",
       "      <td>0.325878</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-21</th>\n",
       "      <td>0.069141</td>\n",
       "      <td>0.008611</td>\n",
       "      <td>0.053009</td>\n",
       "      <td>-0.019663</td>\n",
       "      <td>1659.754150</td>\n",
       "      <td>0.038734</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-22</th>\n",
       "      <td>-0.019926</td>\n",
       "      <td>-0.023784</td>\n",
       "      <td>-0.006771</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>1627.118164</td>\n",
       "      <td>-0.028517</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1901 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Open      High       Low     Close    Adj Close    Volume  \\\n",
       "Date                                                                        \n",
       "2017-11-09       NaN       NaN       NaN       NaN          NaN       NaN   \n",
       "2017-11-10  0.038964 -0.014369 -0.040755 -0.067411   320.884003 -0.008132   \n",
       "2017-11-11 -0.068871 -0.016214  0.012392  0.051555   299.252991 -0.049307   \n",
       "2017-11-12  0.053934 -0.000939  0.001077 -0.021523   314.681000  0.915562   \n",
       "2017-11-13 -0.024357  0.029021  0.028515  0.028606   307.907990 -0.354259   \n",
       "...              ...       ...       ...       ...          ...       ...   \n",
       "2023-01-18 -0.005966  0.005085 -0.028270 -0.033383  1567.846069  0.362581   \n",
       "2023-01-19 -0.033456 -0.027549  0.003284  0.024447  1515.506958 -0.378782   \n",
       "2023-01-20  0.024500  0.065415  0.020165  0.069046  1552.556519  0.325878   \n",
       "2023-01-21  0.069141  0.008611  0.053009 -0.019663  1659.754150  0.038734   \n",
       "2023-01-22 -0.019926 -0.023784 -0.006771  0.000023  1627.118164 -0.028517   \n",
       "\n",
       "            day_of_week  \n",
       "Date                     \n",
       "2017-11-09            3  \n",
       "2017-11-10            4  \n",
       "2017-11-11            5  \n",
       "2017-11-12            6  \n",
       "2017-11-13            0  \n",
       "...                 ...  \n",
       "2023-01-18            2  \n",
       "2023-01-19            3  \n",
       "2023-01-20            4  \n",
       "2023-01-21            5  \n",
       "2023-01-22            6  \n",
       "\n",
       "[1901 rows x 7 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eth['Adj Close'] = eth['Adj Close'].shift(-1)\n",
    "\n",
    "eth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop adj close column\n",
    "eth = eth.drop(['Close'], axis=1)\n",
    "\n",
    "# drop nan values\n",
    "eth = eth.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Open         0\n",
       "High         0\n",
       "Low          0\n",
       "Close        0\n",
       "Volume    2383\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the number on infs\n",
    "eth.isin([np.inf, -np.inf]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change all the infs to 0\n",
    "eth = eth.replace([np.inf, -np.inf], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into x and y train and test using built-in function\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = eth.drop(['Adj Close'], axis=1)\n",
    "y = eth['Adj Close']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42, shuffle=False)\n",
    "\n",
    "# scale the data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-21 16:06:37.636495: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-01-21 16:06:37.636554: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8034, 288, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16242/546366864.py:20: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasRegressor(build_fn=create_model, verbose=0)\n",
      "2023-01-21 16:06:44.610546: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-01-21 16:06:44.611376: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-01-21 16:06:44.611479: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-01-21 16:06:44.611499: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-01-21 16:06:44.620682: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-01-21 16:06:44.620714: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-01-21 16:06:44.620732: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-01-21 16:06:44.620752: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-01-21 16:06:44.626644: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-01-21 16:06:44.626680: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-01-21 16:06:44.636086: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-01-21 16:06:44.636118: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-01-21 16:06:44.648766: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-01-21 16:06:44.648863: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-01-21 16:06:44.672387: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-01-21 16:06:44.672506: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-01-21 16:06:54.019275: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-01-21 16:06:54.019275: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-01-21 16:06:54.019431: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-01-21 16:06:54.020581: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-01-21 16:06:54.058123: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-01-21 16:06:54.058134: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-01-21 16:06:54.058167: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-01-21 16:06:54.058316: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (olli-UX430UNR): /proc/driver/nvidia/version does not exist\n",
      "2023-01-21 16:06:54.058316: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (olli-UX430UNR): /proc/driver/nvidia/version does not exist\n",
      "2023-01-21 16:06:54.058324: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (olli-UX430UNR): /proc/driver/nvidia/version does not exist\n",
      "2023-01-21 16:06:54.058933: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-01-21 16:06:54.059076: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (olli-UX430UNR): /proc/driver/nvidia/version does not exist\n",
      "2023-01-21 16:06:54.123376: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-01-21 16:06:54.123446: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-01-21 16:06:54.123519: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (olli-UX430UNR): /proc/driver/nvidia/version does not exist\n",
      "2023-01-21 16:06:54.137257: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-21 16:06:54.137303: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-21 16:06:54.137300: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-21 16:06:54.137293: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-21 16:06:54.137665: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-21 16:06:54.146182: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-01-21 16:06:54.146274: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-01-21 16:06:54.146348: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (olli-UX430UNR): /proc/driver/nvidia/version does not exist\n",
      "2023-01-21 16:06:54.147219: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-21 16:06:54.161813: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-01-21 16:06:54.161862: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-01-21 16:06:54.161899: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (olli-UX430UNR): /proc/driver/nvidia/version does not exist\n",
      "2023-01-21 16:06:54.162327: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-21 16:06:54.188479: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-01-21 16:06:54.188511: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-01-21 16:06:54.188536: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (olli-UX430UNR): /proc/driver/nvidia/version does not exist\n",
      "2023-01-21 16:06:54.188829: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/olli/Desktop/KoodauskrÃ¤Ã¤sÃ¤Ã¤/trading-strategy-testing/lstm_intraday_gridsearch.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 64>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/olli/Desktop/Koodauskr%C3%A4%C3%A4s%C3%A4%C3%A4/trading-strategy-testing/lstm_intraday_gridsearch.ipynb#X11sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m \u001b[39m# Perform the grid search\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/olli/Desktop/Koodauskr%C3%A4%C3%A4s%C3%A4%C3%A4/trading-strategy-testing/lstm_intraday_gridsearch.ipynb#X11sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m grid \u001b[39m=\u001b[39m GridSearchCV(estimator\u001b[39m=\u001b[39mmodel, param_grid\u001b[39m=\u001b[39mparam_grid, n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/olli/Desktop/Koodauskr%C3%A4%C3%A4s%C3%A4%C3%A4/trading-strategy-testing/lstm_intraday_gridsearch.ipynb#X11sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m grid_result \u001b[39m=\u001b[39m grid\u001b[39m.\u001b[39;49mfit(x_train_seq, y_train_seq, validation_data\u001b[39m=\u001b[39;49m(x_test_seq, y_test_seq))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/olli/Desktop/Koodauskr%C3%A4%C3%A4s%C3%A4%C3%A4/trading-strategy-testing/lstm_intraday_gridsearch.ipynb#X11sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m \u001b[39m# Print the best parameters and the corresponding score\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/olli/Desktop/Koodauskr%C3%A4%C3%A4s%C3%A4%C3%A4/trading-strategy-testing/lstm_intraday_gridsearch.ipynb#X11sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mBest: \u001b[39m\u001b[39m%f\u001b[39;00m\u001b[39m using \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (grid_result\u001b[39m.\u001b[39mbest_score_, grid_result\u001b[39m.\u001b[39mbest_params_))\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    869\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[1;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    871\u001b[0m     )\n\u001b[1;32m    873\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m--> 875\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[1;32m    877\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    879\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:1375\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1374\u001b[0m     \u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1375\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:822\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    815\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    817\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    818\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[1;32m    819\u001b[0m         )\n\u001b[1;32m    820\u001b[0m     )\n\u001b[0;32m--> 822\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    823\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    824\u001b[0m         clone(base_estimator),\n\u001b[1;32m    825\u001b[0m         X,\n\u001b[1;32m    826\u001b[0m         y,\n\u001b[1;32m    827\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[1;32m    828\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[1;32m    829\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[1;32m    830\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[1;32m    831\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[1;32m    832\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[1;32m    833\u001b[0m     )\n\u001b[1;32m    834\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[1;32m    835\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[1;32m    836\u001b[0m     )\n\u001b[1;32m    837\u001b[0m )\n\u001b[1;32m    839\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    840\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    844\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py:1056\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1053\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1055\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1056\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[1;32m   1057\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1058\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py:935\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    933\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    934\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m--> 935\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[1;32m    936\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    937\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py:542\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    540\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 542\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m    543\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    544\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.8/concurrent/futures/_base.py:439\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m    437\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[0;32m--> 439\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_condition\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    441\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    442\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m/usr/lib/python3.8/threading.py:302\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    301\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 302\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    303\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    304\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# LSTM model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def create_model(optimizer='adam', dropout_rate=0.2, num_neurons=50):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(num_neurons, activation=\"relu\", return_sequences=True))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(LSTM(num_neurons, activation=\"relu\", return_sequences=False))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(25))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer=optimizer, loss='mean_absolute_error')\n",
    "    return model\n",
    "\n",
    "# Reshape the data\n",
    "x_train = x_train.reshape(x_train.shape[0], 1, x_train.shape[1])\n",
    "x_test = x_test.reshape(x_test.shape[0], 1, x_test.shape[1])\n",
    "\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "\n",
    "model = create_model(optimizer='adam', dropout_rate=0.0, num_neurons=100)\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=64, validation_data=(x_test, y_test), shuffle=False)\n",
    "\n",
    "# predict the values\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# print the mean absolute error\n",
    "print(mean_absolute_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # plot the loss\n",
    "    plt.plot(model.history.history['loss'], label='train')\n",
    "    plt.plot(model.history.history['val_loss'], label='test')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the prediction and the test set with test set index\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.plot(y_test.index, y_test, label='Test Set')\n",
    "plt.plot(y_test.index, y_pred, label='Prediction')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, Nov 14 2022, 12:59:47) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
